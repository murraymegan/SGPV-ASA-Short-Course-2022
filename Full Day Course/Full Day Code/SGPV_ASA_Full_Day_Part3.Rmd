---
title: Part 3 - ASA Short Course <br> Second-generation p-values (Full-Day) 
output: 
  html_document:
    code_folding: hide
    number_sections: yes
    toc: yes
    toc_depth: 3
    toc_float: yes
    theme: sandstone
---

# Introduction {-}

+ Jeffrey D. Blume, PhD
    + School of Data Science, University of Virginia
+ Megan H. Murray, PhD
    + Department of Biostatistics, Vanderbilt University
    
Resources:

+ GitHub with Slides and Code: [www.github.com/murraymegan/SGPV-ASA-Short-Course-2022](www.github.com/murraymegan/SGPV-ASA-Short-Course-2022)
+ RStudio Desktop: [www.rstudio.com/products/rstudio/download](www.rstudio.com/products/rstudio/download)  
+ Interrupt or use Zoom chat for questions! 
+ For technical difficulties email Megan: [megan.c.hollister@vanderbilt.edu](mailto:megan.c.hollister@vanderbilt.edu)

```{r setup, echo=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(message=FALSE, warning=FALSE, echo=TRUE)

## load all needed packages
library(sgpv)
library(ggplot2)
library(dplyr)
library(kableExtra)
library(latex2exp)
library(ProSGPV)

## load data
data(leukstats)
data(lung)
```

# Part 3

## Part 3a

### ProSGPV Simulation

+ We first present an example by applying the ProSGPV algorithm to a simulated dataset by use of gen.sim.data function.

+ With sample size n = 100, number of variables p = 10, number of true signals s = 4, smallest effect size $\beta_{min}$ = 1, largest effect size $\beta_{max}$ = 5, autoregressive correlation ρ = 0.2 and variance σ2 = 1, signal-to-noise ratio (SNR) $\nu$= 2.

+ We generate outcomes Y following Gaussian distribution. `gen.sim.data` outputs X, Y, indices of true signals, and a vector of true coefficients.

```{r}
set.seed(1)
sim.data <- gen.sim.data(n = 50, p = 10, s = 4,
                         family = "gaussian",
                         beta.min = 1, beta.max = 5,
                         rho = 0.2, nu = 2)
x <- sim.data[[1]]
y <- sim.data[[2]]
(true.index <- sim.data[[3]])

true.beta <- sim.data[[4]]
```

+ By default, the two-stage algorithm is used in ProSGPV. 
+ `pro.sgpv` function takes inputs of explanatory variables x, outcome y, outcome type family (default is “gaussian”), stage indicator (default is 2), and a GVIF indicator (default is FALSE). 
+ A print method is available to show labels of the variables selected by ProSGPV.

```{r}
sgpv.out.2 <- pro.sgpv(x,y)
sgpv.out.2

# true.beta
true.index
```

+  Visualization of variable selection process

```{r}
plot(sgpv.out.2)
```

Model Summary

```{r}
summary(sgpv.out.2)
```

+ `coef` function can be used to extract the coefficient estimates of length p. When signals are sparse, some of estimates are zero. A comparison shows that the estimates are close to the true effect sizes in the simulation.

```{r}
beta.hat = coef(sgpv.out.2)
rbind(beta.hat, true.beta)
```

+ `predict` function can be used to predict outcomes using the selected model. 
+ In-sample prediction can be made by calling `predict(sgpv.out.2)` and out-of-sample prediction can be made by feeding new data set into the newdata argument.

```{r}
preds = predict(sgpv.out.2)

cbind(preds, y)
```

In addition to the two-stage algorithm, one-stage algorithm can also be used to select variables when n > p. The computation time is shorter for the one-stage algorithm at the expense of slightly reduced support recovery rate in the limit.

```{r}
sgpv.out.1 <- pro.sgpv(x,y,stage=1)
sgpv.out.1
```

The one-stage algorithm missed V4 and only selected three variables. What happened?

```{r}
plot(sgpv.out.1)
```

### ProSGPV Real Life Example

We can load the Tehran Housing data `t.housing` stored in the package.

A dataset containing Tehran housing data. The data set has 372 observations. There are 26 explanatory variables at baseline, including 7 project physical and financial features (V2-V8) and 19 economic variables and indices (V11-V29). The outcome (V9) is the sales price of a real estate single-family residential apartment.

```{r}
set.seed(999)

# prepare the data
x = t.housing[,-ncol(t.housing)]
y = t.housing$V9

# run ProSGPV
out.sgpv.2 <- pro.sgpv(x = x, y = y)
```

The two-stage algorithm selects the following variables.

```{r}
out.sgpv.2
```

+ V9: Actual sales price (outcome)
+ V8: Price of the unit at the beginning of the project per square meter
+ V12: Building services index for preselected base year
+ V13: Wholesale price index of building materials for the base year
+ V15: Cumulative liquidity
+ V17: Land price index for the base year
+ V26: CPI of housing, water, fuel & power in the base year

We can view the summary of the final model.

```{r}
summary(out.sgpv.2)
```

Coefficient estimates can be extracted by use of coef.

```{r}
coef(out.sgpv.2)
```

In-sample prediction can be made using S3 method predict and an external sample can be provided to make out-of-sample prediction with an argument of newx in the predict function.

```{r}
head(predict(out.sgpv.2))
```

S3 method plot can be used to visualize the variable selection process.

First, we plot the full solution path with point estimates and 95% confidence intervals. Note that the null region is in grey. The selected variables are colored blue on the y-axis. `lambda.max` controls the limit of the X-axis.

```{r}
plot(out.sgpv.2, lambda.max = 0.01)
```

Alternatively, we can plot the confidence bound that is closer to the null.

```{r}
plot(out.sgpv.2,lpv=1,lambda.max=0.01)
```

## Part 3b

### Vignettes {-}

+ [Linear ProSGPV](https://cran.r-project.org/web/packages/ProSGPV/vignettes/linear-vignette.html )

+ [GLM and Cox ProSGPV](https://cran.r-project.org/web/packages/ProSGPV/vignettes/glm-cox-vignette.html)


