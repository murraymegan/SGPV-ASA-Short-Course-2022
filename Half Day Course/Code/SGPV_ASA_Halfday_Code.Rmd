---
title: ASA Short Course <br> Second-generation p-values (Half-Day)
output: 
  html_document:
    code_folding: hide
    number_sections: no
    toc: yes
    toc_depth: 2
    toc_float: yes
    theme: sandstone
---

# Introduction

+ Jeffrey D. Blume, PhD
    + School of Data Science, University of Virginia
+ Megan H. Murray, almost PhD (July 6th defense)
    + Department of Biostatistics, Vanderbilt University
    
Resources:

+ GitHub with Slides and Code: [www.github.com/murraymegan/SGPV-ASA-Short-Course](www.github.com/murraymegan/SGPV-ASA-Short-Course)
+ RStudio Desktop: [www.rstudio.com/products/rstudio/download](www.rstudio.com/products/rstudio/download)  
+ Interrupt or use Zoom chat for questions! 
+ For technical difficulties email Megan: [megan.c.hollister@vanderbilt.edu](mailto:megan.c.hollister@vanderbilt.edu)

```{r setup, echo=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(message=FALSE, warning=FALSE, echo=TRUE)

## load packages
library(sgpv)
library(ggplot2)
library(dplyr)
library(kableExtra)
library(FDRestimation)
library(survival)

## load data
data(leukstats)
data(lung)
```

# Part 1

## Part 1a

### SGPV R Package

Install `sgpv` package. 

```{r eval=FALSE}
#GitHub
install.packages("devtools")
devtools::install_github("weltybiostat/sgpv")

#CRAN
install.packages("sgpv")
```

### Systolic Blood Pressure


```{r}
options(digits=5)
#function
xbar<-c(.5,1,1.1,1.1,1.1)
se<-c(.2,.2,.2,.1,.05)

p.plot<-function(xbar,se,delta.a,delta.b,h0,side='right'){
  lb<-xbar-1.96*se
  ub<-xbar+1.96*se
  z1<-(xbar-h0)/se
  p1<-round(2*pnorm(-abs(z1)),5)
  z2<-ifelse(abs(xbar-delta.b)< abs(xbar-delta.a),(xbar-delta.b)/se,(xbar-delta.a)/se)
  z2<-ifelse(xbar>delta.b | delta.a > xbar,z2,0)
  p2<-round(2*pnorm(-abs(z2)),5)
  p3<-correction<-NULL
  
  for (i in 1:length(xbar)){
    p3[i]<-ifelse((lb[i] <delta.b & ub[i]>delta.b )|(lb[i] < delta.a & ub[i] > delta.a),min((delta.b-lb[i])/(ub[i]-lb[i]),(delta.b-delta.a)/(ub[i]-lb[i]),(ub[i]-delta.a)/(ub[i]-lb[i])),1)
    #emphasis on null hypothesis adjustment
    correction[i]<-max((ub[i]-lb[i])/(2*(delta.b-delta.a)),1)
  }
  p3<-ifelse(lb>delta.b,0,p3)
  p3<-ifelse(ub< delta.a,0,p3)
  p4<-ifelse(p3 != 0 & p3 != 1,p3*p2,p3)
  p5<-p3*correction
  
  if(side=='right'){
    
    plot(c(xbar,NA),1:(length(xbar)+1),xlim=c(min(lb,delta.a),max(ub)+5),xaxt='n',yaxt='n',ylab="",xlab="")
    abline(v=h0,lty=2,lwd=2,col='red')
    points(c(xbar,NA),1:(length(xbar)+1))
    for  (i in 1:length(xbar)){
      lines(c(lb[i],ub[i]),c(i,i))
    }
    rect(delta.a,length(xbar)+1,delta.b,0,col=rgb(1,0,0,.5))
    text(max(ub)+.5,1:(length(xbar)+1),c(round(p5,4),"A better P-value"))
    #text(max(ub)+.5,1:(length(xbar)+1),c(round(p4,4),"Proportion*Max P-value"))
    #text(max(ub)+2,1:(length(xbar)+1),c(round(p3,4),"Proportion in Null"))
    text(max(ub)+2.5,1:(length(xbar)+1),c(round(p2,4),"Max P-value"))
    text(max(ub)+4.5,1:(length(xbar)+1),c(round(p1,4),"Traditional P-value"))
    axis(side = 1,at=seq(round(min(lb)),round(max(ub)),delta.b-h0))
  }else if (side=='left'){
    
    plot(c(xbar,NA),1:(length(xbar)+1),xlim=c(min(lb)-7,max(ub,delta.b)),xaxt='n',yaxt='n',ylab="",xlab="")
    abline(v=h0,lty=2,lwd=2,col='red')
    points(c(xbar,NA),1:(length(xbar)+1))
    for  (i in 1:length(xbar)){
      lines(c(lb[i],ub[i]),c(i,i))
    }
    rect(delta.a,length(xbar)+1,delta.b,0,col=rgb(1,0,0,.5))
    text(min(lb)-6.5,1:(length(xbar)+1),c(c("Study 8","Study 7","Study 6","Study 5","Study 4","Study 3","Study 2","Study 1")," "),font=2)
    text(min(lb)-4.5,1:(length(xbar)+1),c(round(p5,4),expression(P[delta]-value)))
    text(min(lb)-2.5,1:(length(xbar)+1),c(round(p2,4),"Max P-value"))
    text(min(lb)-.5,1:(length(xbar)+1),c(ifelse(round(p1,4)>0.0001 |round(p1,4)==0,round(p1,4),"<0.0001"),"Traditional P-value"))
    axis(side = 1,at=seq(round(min(lb,delta.a)),round(max(ub,delta.b)),delta.b-h0))
  }
  return(cbind(lb,ub))
}
```

```{r}
#plot for paper
 p.plot(xbar=c(120,120,120.5,121,122,122),se=c(.4,1,.4,.4,1,.4),delta.a=119,delta.b=121,h0=120)
 
p.plot(xbar=c(140,141,142.5,143,145,144,144.5,145),se=c(.5,1,.5,1,2.25,1.25,.25,.5),delta.a=143,delta.b=147,h0=145,'left')

```

### BOMAMI

+ European Heart Journal: [https://academic.oup.com/eurheartj/article/32/14/1748/527618](https://academic.oup.com/eurheartj/article/32/14/1748/527618)

```{r}
##########################
###### BOMAMI Trial Slide 28 and 29

## OR 
sgpvalue(est.lo=0.967, est.hi=7.286, null.lo=0.9, null.hi=1.11)$p.delta

## RR
sgpvalue(est.lo=0.953, est.hi=4.589, null.lo=0.9, null.hi=1.11)$p.delta

## RD
sgpvalue(est.lo=0.003, est.hi=0.352, null.lo=-0.1, null.hi=0.1)$p.delta
sgpvalue(est.lo=0.003, est.hi=0.352, null.lo=-0.05, null.hi=0.05)$p.delta
```

```{r}
## Logistic Regression Slide 30

##########################
###### BOMAMI Trial

## Primary OR
p1 = sgpvalue(est.lo=1.18, est.hi=20.19, null.lo=0.9, null.hi=1.11)$p.delta
# sgpvalue(est.lo=1.18, est.hi=20.19, null.lo=0.8, null.hi=1.2)

## Covariates
p2 = sgpvalue(est.lo=1.09, est.hi=19.28, null.lo=0.9, null.hi=1.11)$p.delta
p3 = sgpvalue(est.lo=0.86, est.hi=38.29, null.lo=0.9, null.hi=1.11)$p.delta

p4 = sgpvalue(est.lo=0.66, est.hi=8.98, null.lo=0.9, null.hi=1.11)$p.delta
p5 = sgpvalue(est.lo=0.36, est.hi=26.92, null.lo=0.9, null.hi=1.11)$p.delta

p6 = sgpvalue(est.lo=0.95, est.hi=1.11, null.lo=0.9, null.hi=1.11)$p.delta
p7 = sgpvalue(est.lo=0.09, est.hi=1.59, null.lo=0.9, null.hi=1.11)$p.delta


kable(cbind(c("Variable",
              "group", 
              "tobacco",
              "microvascular obstroction",
              "dyslipidemia",
              "gender",
              "age",
              "hypertension"), c("SGPV",p1,round(p2,3),p3,p4,p5,p6,p7)), format = "html", table.attr = "style='width:50%;'") %>%
  kable_styling(c("striped", "bordered"))
```

### Lung Cancer Survival

```{r}
fit<- survfit(Surv(time, status) ~ sex, data = lung)
plot(fit,col=c("red","blue"))
# summary(fit)
# objects(fit)
# summary(fit)$surv

newdata=lung$sex

lung.Surv <- with(lung, Surv(time=time, event=status))
lung.survfit <- survfit(lung.Surv ~ lung$sex)

sCox <- coxph(lung.Surv ~ as.factor(sex),data=lung)
```

```{r}
pred.1=summary(survfit(sCox,newdata=data.frame(sex=1)))$surv
pred.2=summary(survfit(sCox,newdata=data.frame(sex=2)))$surv
pred.diff=pred.2-pred.1
time.diff=summary(survfit(sCox,newdata=data.frame(sex=1)))$time
v.1=summary(survfit(sCox,newdata=data.frame(sex=1)))$std.err^2
v.2=summary(survfit(sCox,newdata=data.frame(sex=2)))$std.err^2
se.diff=sqrt(v.1+v.2)

lb=pred.diff-1.96*se.diff
ub=pred.diff+1.96*se.diff

pdelt <- sgpvalue(lb,ub,-0.05,0.05)$p.delta
```

```{r}
#colors
colfunc <- colorRampPalette(c("grey90", "gray44"))
COL <- ifelse(pdelt == 0,"#00ea6e",
              ifelse(pdelt == 1, "#ff0000",
                     colfunc(length(unique(pdelt[!(pdelt %in% c(0,1))])))[as.numeric(cut(pdelt[!(pdelt %in% c(0,1))],breaks = length(unique(pdelt[!(pdelt %in% c(0,1))]))))]))


plot(lung.survfit,col=c("dodgerblue1","hotpink"),mark.time=F,lwd=c(2,2),
	ylab="Survival",xlab="") ## sex=1 is hotpink
for (i in 1:length(time.diff)){rug(time.diff[i],col=COL[i],lwd=1.2,ticksize=0.04)}
axis(side=1)
mtext("Days",side=1,line=2.25)

legend(750,1,c("Females","Males"),col=c("hotpink","dodgerblue1"),lty=1,lwd=2,bty="n")
text(900,0.82,"ID zone is +/- 5%")

par(xpd=TRUE)
legend(125,-0.175,c("pdelta=0","0 < pdelta < 1","pdelta=1"),text.width=c(60,120,150),
		col=c("#00ea6e","#D8D8D8","#ff0000"),lwd=2,lty=1,horiz=TRUE,bty="n")
par(xpd=FALSE)
```

```{r}
## CI plot to illustrate...

par(xpd=FALSE)
plot(time.diff,pred.diff,ylim=c(-0.1,0.35),xlab="",ylab="Difference",type="n")
axis(side=1)
mtext("Days",side=1,line=2.25)
rect(0,-0.05,max(time.diff),0.05,col=rgb(208,216,232,max=255),border=NA)
lines(time.diff,pred.2-pred.1,lwd=2,col="black")
abline(h=0,lty=2,lwd=0.5)

lines(time.diff,ub,lty=2,col="red")
lines(time.diff,lb,lty=2,col="red")

for (i in 1:length(time.diff)){rug(time.diff[i],col=COL[i],lwd=1.2,ticksize=0.04)}
axis(side=1)
par(xpd=TRUE)
legend(125,-0.175,c("pdelta=0","0 < pdelta < 1","pdelta=1"),text.width=c(60,120,150),
		col=c("#00ea6e","#D8D8D8","#ff0000"),lwd=2,lty=1,horiz=TRUE,bty="n")
par(xpd=FALSE)

legend(675,0.37,c("Difference","95% CI"),col=c("black","red"),lty=c(1,2),lwd=2,bty="n")

text(800,0.31,"ID zone is +/- 5%")
```




## Part 1b

### Plots

```{r}

##########################
###### Leukemia Example

data(leukstats)
plotsgpv(est.lo=leukstats$ci.lo, est.hi=leukstats$ci.hi,
		null.lo=-0.3, null.hi=0.3,
		set.order=order(leukstats$p.value),
		x.show=7000,
		plot.axis=c("TRUE","FALSE"),
		null.pt=0, outline.zone=TRUE,
		title.lab="Leukemia Example", y.lab="Fold Change (base 10)",
		x.lab="Classical p-value ranking",
		legend.on=TRUE)
axis(side=2,at=round(log(c(1/1000,1/100,1/10,1/2,1,2,10,100,1000),
	base=10),2),labels=c("1/1000","1/100","1/10","1/2",1,2,10,100,1000),
	las=2)
```

# Part 2

6 properties- load functions
study planning

null.delta-scalar 1/2
n-scalar 10
theta-scalar 1

theta0-0
sigma-1
alpha-0.05

## SGPV False Discovery Risk

```{r}
##########################
###### FDR rates

fdrisk(sgpval = 0,  null.lo = log(1/1.1), null.hi = log(1.1),  std.err = 0.8,  null.weights = 'Uniform',  null.space = c(log(1/1.1), log(1.1)),  alt.weights = 'Uniform',  alt.space = 2 + c(-1,1)*qnorm(1-0.05/2)*0.8,  interval.type = 'confidence',  interval.level = 0.05)
fdrisk(sgpval = 0,  null.lo = log(1/1.1), null.hi = log(1.1),  std.err = 0.8,  null.weights = 'Point',  null.space = 0,  alt.weights = 'TruncNormal',  alt.space = 2 + c(-1,1)*qnorm(1-0.041/2)*0.8,  interval.type = 'likelihood',  interval.level = 1/8)
fdrisk(sgpval = 0,  null.lo = log(1/1.5), null.hi = log(1.5),  std.err = 0.8,  null.weights = 'Point',  null.space = 0,  alt.weights = 'Uniform',  alt.space = 2.5 + c(-1,1)*qnorm(1-0.041/2)*0.8,  interval.type = 'likelihood',  interval.level = 1/8)
fdrisk(sgpval = 1,  null.lo = log(1/1.5), null.hi = log(1.5),  std.err = 0.15,  null.weights = 'Uniform',  null.space = 0.01 + c(-1,1)*qnorm(1-0.041/2)*0.15,  alt.weights = 'Uniform',  alt.space = c(log(1.5), 1.25*log(1.5)),  interval.type = 'likelihood',  interval.level = 1/8)

###
##
#
```

## FDRestimation

Download the package from:
https://cran.r-project.org/package=FDRestimation

OR https://github.com/murraymegan/FDRestimation 

Our corresponding paper: https://arxiv.org/abs/2010.04680 

PDF: https://arxiv.org/pdf/2010.04680.pdf 


```{r}
p.fdr.output = p.fdr(leukstats$p.value)

head(p.fdr.output$`Results Matrix`)

summary(p.fdr.output)

plot(p.fdr.output)

get.pi0(leukstats$p.value, estim.method = "last.hist")
get.pi0(leukstats$p.value, estim.method = "storey")
get.pi0(leukstats$p.value, estim.method = "set.pi0", set.pi0=0.8)

plot(p.fdr.output, xlim=c(1100,1600), ylim=c(0, 0.2))

which(-1*(p.fdr.output$`Results Matrix`$`Adjusted p-values`)+p.fdr.output$fdrs>0.001)

#Benjamini-Yeukatelli
p.fdr.output = p.fdr(leukstats$p.value, adjust.method = "BY")

head(p.fdr.output$`Results Matrix`)

plot(p.fdr.output)

plot(p.fdr.output, xlim=c(2000,2400), legend.on = FALSE)
```

### Simple Example

```{r}
pvalues=c(0.005,0.049,0.05,0.051,0.7)
zvalues=qnorm(pvalues/2, lower.tail = FALSE)

p.fdr.output = p.fdr(pvalues)

adj.pvalues= p.fdr.output$`Results Matrix`$`Adjusted p-values`
adj.fdrs= p.fdr.output$fdrs

single.fdr = c(p.fdr(pvalues=pvalues[1],zvalue=zvalues[1]),
               p.fdr(pvalues=pvalues[2],zvalue=zvalues[2]),
               p.fdr(pvalues=pvalues[3],zvalue=zvalues[3]),
               p.fdr(pvalues=pvalues[4],zvalue=zvalues[4]),
               p.fdr(pvalues=pvalues[5],zvalue=zvalues[5]))
```

```{r}
df = data.frame("Raw p-values"= pvalues, 
                "Z-values" = zvalues,
                "BH Adj p-values" = adj.pvalues,
                "BH FDRs" = adj.fdrs,
                "Single lower bound FDRs" = single.fdr)

colnames(df) = c("Raw p-values", 
                "Z-values",
                "BH Adj p-values"  ,
                "BH FDRs" ,
                "Single lower bound FDRs" )
                
kable(round(df,3))%>%
  kable_styling(c("striped", "bordered"))
```

### Compare FDRestimation to p.adjust

```{r}
set.seed(999)
pi0 <- 0.8
pi1 <- 1-pi0
n <- 10
n.0 <- ceiling(n*pi0)
n.1 <- n-n.0

sim.data <- c(rnorm(n.1,2,1),rnorm(n.0,0,1))
sim.data.p <- 2*pnorm(-abs(sim.data))

p.adjust.output = p.adjust(sim.data.p, method="fdr")

fdr.output = p.fdr(pvalues=sim.data.p, adjust.method="BH")

head(data.frame("Raw p-values"= sim.data.p,"p.adjust FDRs"=p.adjust.output,"p.fdr adj p-values"=fdr.output$`Results Matrix`$`Adjusted p-values`,"p.fdr FDRs"=fdr.output$fdrs))

plot(rank(sim.data.p, ties="random"), 
     fdr.output$`Results Matrix`$`Adjusted p-values`, 
     pch=17, 
     col="dodgerblue", 
     cex=2, 
     ylim=c(0,1),
     main="Comparison Plot", 
     xlab="Rank of p-values",
     ylab="")
points(rank(sim.data.p, ties="random"),p.adjust.output, pch=20, col="pink")
points(rank(sim.data.p, ties="random"),fdr.output$fdrs, pch=20, col="firebrick")
legend("bottomright", c("p.adjust FDRs", "p.fdr FDRs","p.fdr Adjusted p-values"), col=c("pink", "firebrick","dodgerblue"), pch=c(20,20,17))
```

### Different Null proportion

```{r}
set.seed(999)
pi0 <- 0.8
pi1 <- 1-pi0
n <- 100
n.0 <- ceiling(n*pi0)
n.1 <- n-n.0

sim.data <- c(rnorm(n.1,2,1),rnorm(n.0,0,1))
sim.data.p <- 2*pnorm(-abs(sim.data))

fdr.output = p.fdr(pvalues=sim.data.p, adjust.method="BH")

plot(fdr.output)

fdr.output = p.fdr(pvalues=sim.data.p, adjust.method="BH", set.pi0=0.8)

plot(fdr.output)
```

```{r}
get.pi0(sim.data.p, estim.method = "set.pi0", set.pi0=0.7)
get.pi0(sim.data.p, estim.method = "last.hist")
get.pi0(sim.data.p, estim.method = "storey")

pi0 <- 0.8
pi1 <- 1-pi0
n <- 10000
n.0 <- ceiling(n*pi0)
n.1 <- n-n.0

sim.data <- c(rnorm(n.1,2,1),rnorm(n.0,0,1))
sim.data.p <- 2*pnorm(-abs(sim.data))

get.pi0(sim.data.p, estim.method = "set.pi0", set.pi0=0.7)
get.pi0(sim.data.p, estim.method = "last.hist")
get.pi0(sim.data.p, estim.method = "storey")
```

#### Internal Code: Last Histogram Height Method

```{r}
try.hist = hist(sim.data.p, breaks="scott")
try.mids = try.hist$mids
try.count = try.hist$counts

if(tail(try.mids,1)<0.5){
  pi0.hat=0
}else{
  pi0.hat = min(tail(try.count,1)*length(try.mids)/sum(try.count),1)
}

pi0.hat
```


 ?tsum.test in the BSDA package. For 
 
 https://stackoverflow.com/questions/18919091/generate-random-numbers-with-fixed-mean-and-sd 
 
 https://stackoverflow.com/questions/18919091/generate-random-numbers-with-fixed-mean-and-sd
 
 https://stackoverflow.com/questions/5526922/r-t-test-from-n-mean-sd
 
 50 observations a piece